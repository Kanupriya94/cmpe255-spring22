{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n!pip install --upgrade scikit-learn==0.20.3\n!pip install pydotplus\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nfrom matplotlib import pyplot\n\n\n    \ndef plot_trees(model):\n    estimators = gradient_boosting_model.estimators_\n    for i in range(len(estimators)):\n        tree.plot_tree(estimators[i][0])\n        pyplot.show()\n        #plot_model(new_X, new_y, estimators[i][0])\n        \ndef plot_regressor(model, features, labels):\n    x = np.linspace(0,85,1000)\n    pyplot.scatter(features, labels)\n    pyplot.plot(x, model.predict(x.reshape([-1,1])))\n    pyplot.xlabel(\"Age\")\n    pyplot.ylabel(\"Days per week\")\n    pyplot.show()\n    \nfrom matplotlib import pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T18:21:38.113631Z","iopub.execute_input":"2022-04-27T18:21:38.115931Z","iopub.status.idle":"2022-04-27T18:22:08.289572Z","shell.execute_reply.started":"2022-04-27T18:21:38.113858Z","shell.execute_reply":"2022-04-27T18:22:08.288690Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Some functions to plot our points and draw the lines\ndef plot_points(features, labels, fix_margins=True):\n    X = np.array(features)\n    y = np.array(labels)\n    spam = X[np.argwhere(y==1)]\n    ham = X[np.argwhere(y==0)]\n    if fix_margins:\n        pyplot.xlim(0, 11)\n        pyplot.ylim(0, 11)\n    pyplot.scatter([s[0][0] for s in spam],\n                [s[0][1] for s in spam],\n                s = 100,\n                color = 'cyan',\n                edgecolor = 'k',\n                marker =  '^')\n    pyplot.scatter([s[0][0] for s in ham],\n                [s[0][1] for s in ham],\n                s = 100,\n                color = 'red',\n                edgecolor = 'k',\n                marker = 's')\n    pyplot.xlabel('Lottery')\n    pyplot.ylabel('Sale')\n    pyplot.legend(['Spam','Ham'])\n\ndef plot_model(X, y, model, fix_margins=True):\n    X = np.array(X)\n    y = np.array(y)\n    plot_points(X, y)\n    plot_step = 0.01\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    if fix_margins:\n        x_min=0\n        y_min=0\n        x_max=12\n        y_max=12\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                         np.arange(y_min, y_max, plot_step))\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    pyplot.contourf(xx, yy, Z, colors=['red', 'blue'], alpha=0.2, levels=range(-1,2))\n    pyplot.contour(xx, yy, Z,colors = 'k',linewidths = 3)\n    pyplot.show()\n\ndef display_tree(dt):\n    from sklearn.externals.six import StringIO  \n    from IPython.display import Image  \n    from sklearn.tree import export_graphviz\n    import pydotplus\n    dot_data = StringIO()\n    export_graphviz(dt, out_file=dot_data,  \n                    filled=True, rounded=True,\n                    special_characters=True)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:28:48.252743Z","iopub.execute_input":"2022-04-27T18:28:48.253037Z","iopub.status.idle":"2022-04-27T18:28:48.275471Z","shell.execute_reply.started":"2022-04-27T18:28:48.252997Z","shell.execute_reply":"2022-04-27T18:28:48.274335Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\nnp.random.seed(0)\n\n# Spam Email dataset\nemails = np.array([\n    [7,8,1],\n    [3,2,0],\n    [8,4,1],\n    [2,6,0],\n    [6,5,1],\n    [9,6,1],\n    [8,5,0],\n    [7,1,0],\n    [1,9,1],\n    [4,7,0],\n    [1,3,0],\n    [3,10,1],\n    [2,2,1],\n    [9,3,0],\n    [5,3,0],\n    [10,1,0],\n    [5,9,1],\n    [10,8,1],\n])\nspam_dataset = pd.DataFrame(data=emails, columns=[\"Lottery\", \"Sale\", \"Spam\"])\nspam_dataset\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:28:51.924122Z","iopub.execute_input":"2022-04-27T18:28:51.924404Z","iopub.status.idle":"2022-04-27T18:28:53.145323Z","shell.execute_reply.started":"2022-04-27T18:28:51.924376Z","shell.execute_reply":"2022-04-27T18:28:53.144224Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Decision Tree Classifier**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Max Depth = 2**","metadata":{}},{"cell_type":"code","source":"features = spam_dataset[['Lottery', 'Sale']]\nlabels = spam_dataset['Spam']\nplot_points(features, labels)\n\n# Decision Tree\ndt_clf = DecisionTreeClassifier(max_depth =2, random_state=42)\ndt_clf.fit(features, labels)\ndt_clf.score(features, labels)\n\n# Draw decision tree\ndisplay_tree(dt_clf)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:28:58.244883Z","iopub.execute_input":"2022-04-27T18:28:58.245152Z","iopub.status.idle":"2022-04-27T18:28:59.324058Z","shell.execute_reply.started":"2022-04-27T18:28:58.245120Z","shell.execute_reply":"2022-04-27T18:28:59.323534Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Decision tree as map\nplot_model(features, labels, dt_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:03.000232Z","iopub.execute_input":"2022-04-27T18:29:03.000713Z","iopub.status.idle":"2022-04-27T18:29:03.469685Z","shell.execute_reply.started":"2022-04-27T18:29:03.000680Z","shell.execute_reply":"2022-04-27T18:29:03.468869Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Max Depth = 4**","metadata":{}},{"cell_type":"code","source":"dt_clf = DecisionTreeClassifier(max_depth = 4 ,random_state=42)\ndt_clf.fit(features, labels)\ndt_clf.score(features, labels)\n\n# Draw decision tree\ndisplay_tree(dt_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:05.979946Z","iopub.execute_input":"2022-04-27T18:29:05.980249Z","iopub.status.idle":"2022-04-27T18:29:06.458494Z","shell.execute_reply.started":"2022-04-27T18:29:05.980218Z","shell.execute_reply":"2022-04-27T18:29:06.457471Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Decision tree as map\nplot_model(features, labels, dt_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:09.726122Z","iopub.execute_input":"2022-04-27T18:29:09.726418Z","iopub.status.idle":"2022-04-27T18:29:10.193233Z","shell.execute_reply.started":"2022-04-27T18:29:09.726387Z","shell.execute_reply":"2022-04-27T18:29:10.192214Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Max Depth = 6**","metadata":{}},{"cell_type":"code","source":"dt_clf = DecisionTreeClassifier(max_depth = 6 ,random_state=42)\ndt_clf.fit(features, labels)\ndt_clf.score(features, labels)\n# Draw decision tree\ndisplay_tree(dt_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:13.094434Z","iopub.execute_input":"2022-04-27T18:29:13.095201Z","iopub.status.idle":"2022-04-27T18:29:13.377384Z","shell.execute_reply.started":"2022-04-27T18:29:13.095145Z","shell.execute_reply":"2022-04-27T18:29:13.376439Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Decision tree as map\nplot_model(features, labels, dt_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:17.129129Z","iopub.execute_input":"2022-04-27T18:29:17.129406Z","iopub.status.idle":"2022-04-27T18:29:17.595664Z","shell.execute_reply.started":"2022-04-27T18:29:17.129378Z","shell.execute_reply":"2022-04-27T18:29:17.594358Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# # From above plots we can see:\n\n* max_depth 2: many missclassified points\n* max_depth 4: 2 missclassified points\n* max_depth 6: 1 missclassified points","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# **Random Forest Classifier**","metadata":{}},{"cell_type":"markdown","source":"n_estimators int, default=100\nThe number of trees in the forest.","metadata":{}},{"cell_type":"code","source":"# Training a Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier(random_state=0, n_estimators=10, max_depth=1)\nrf_clf.fit(features, labels)\nrf_clf.score(features, labels)\n\ny_pred = rf_clf.predict(features)\n\n# plot\nplot_model(features, labels, rf_clf)\n\n#Plotting the points\nplot_points(features, labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:23.349365Z","iopub.execute_input":"2022-04-27T18:29:23.349643Z","iopub.status.idle":"2022-04-27T18:29:24.920341Z","shell.execute_reply.started":"2022-04-27T18:29:23.349615Z","shell.execute_reply":"2022-04-27T18:29:24.919502Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\ny_test = labels\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:27.983903Z","iopub.execute_input":"2022-04-27T18:29:27.984205Z","iopub.status.idle":"2022-04-27T18:29:27.994205Z","shell.execute_reply.started":"2022-04-27T18:29:27.984174Z","shell.execute_reply":"2022-04-27T18:29:27.993570Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(5, 5))\nax = sns.distplot(y_test, hist=False, color=\"y\", label=\"Actual Value\")\nsns.distplot(y_pred, hist=False, color=\"g\", label=\"Predicted Values\" , ax=ax)\nplt.title('Random Forest Classifier: Actual Vs Fitted')\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:34.329180Z","iopub.execute_input":"2022-04-27T18:29:34.329501Z","iopub.status.idle":"2022-04-27T18:29:34.725813Z","shell.execute_reply.started":"2022-04-27T18:29:34.329471Z","shell.execute_reply":"2022-04-27T18:29:34.724877Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"rf_clf = RandomForestClassifier(random_state=0, n_estimators=20, max_depth=2)\nrf_clf.fit(features, labels)\nrf_clf.score(features, labels)\ny_pred = rf_clf.predict(features)\n# plot\nplot_model(features, labels, rf_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:38.885436Z","iopub.execute_input":"2022-04-27T18:29:38.886048Z","iopub.status.idle":"2022-04-27T18:29:41.105025Z","shell.execute_reply.started":"2022-04-27T18:29:38.885987Z","shell.execute_reply":"2022-04-27T18:29:41.104223Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Make predictions on test data\ny_pred = rf_clf.predict(features)\n# Performance metrics\nerrors = abs(y_pred - labels)\n\nprint('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n# Calculate mean absolute percentage error (MAPE)\nmean_absolute_percentage_error = np.mean(100 * (errors / labels))\n# Calculate and display accuracy\naccuracy = 100 - mean_absolute_percentage_error\nprint('Accuracy: ', round(accuracy, 2), '%.')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:45.023890Z","iopub.execute_input":"2022-04-27T18:29:45.024960Z","iopub.status.idle":"2022-04-27T18:29:45.039694Z","shell.execute_reply.started":"2022-04-27T18:29:45.024898Z","shell.execute_reply":"2022-04-27T18:29:45.039109Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# **Adaboost Classifier**","metadata":{}},{"cell_type":"markdown","source":"n_estimatorsint, default=50\nThe maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.","metadata":{}},{"cell_type":"code","source":"# Training a AdaBoost\n!pip install scipy\nfrom sklearn.ensemble import AdaBoostClassifier\n\nab_clf = AdaBoostClassifier(n_estimators=100, random_state=0)\nab_clf.fit(features, labels)\n\nab_clf.score(features, labels)\n\nplot_model(features, labels, ab_clf)\nplot_points(features, labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:29:47.353294Z","iopub.execute_input":"2022-04-27T18:29:47.353688Z","iopub.status.idle":"2022-04-27T18:30:08.747406Z","shell.execute_reply.started":"2022-04-27T18:29:47.353659Z","shell.execute_reply":"2022-04-27T18:30:08.746744Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Make predictions on test data\ny_pred = ab_clf.predict(features)\n\n# Performance metrics\nerrors = abs(y_pred - labels)\n\nprint('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n# Calculate mean absolute percentage error (MAPE)\nmape = np.mean(100 * (errors / labels))\n# Calculate and display accuracy\naccuracy = 100 - mape\nprint('Accuracy:', round(accuracy, 2), '%.')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:30:08.803865Z","iopub.execute_input":"2022-04-27T18:30:08.804099Z","iopub.status.idle":"2022-04-27T18:30:08.832789Z","shell.execute_reply.started":"2022-04-27T18:30:08.804069Z","shell.execute_reply":"2022-04-27T18:30:08.831526Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(5, 5))\nax = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(y_pred, hist=False, color=\"g\", label=\"Fitted Values\" , ax=ax)\nplt.title('AdaBoost Classifications: Actual vs Fitted')\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:30:08.835366Z","iopub.execute_input":"2022-04-27T18:30:08.835640Z","iopub.status.idle":"2022-04-27T18:30:09.008863Z","shell.execute_reply.started":"2022-04-27T18:30:08.835611Z","shell.execute_reply":"2022-04-27T18:30:09.007712Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_pred_nb = y_pred\nytest = labels\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n\nacc = accuracy_score(ytest, y_pred_nb)\nprec = precision_score(ytest, y_pred_nb)\nrec = recall_score(ytest, y_pred_nb)\nf1 = f1_score(ytest, y_pred_nb)\nroc=roc_auc_score(ytest, y_pred_nb)\n\nmodel= pd.DataFrame([['Adaboost', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:30:15.543917Z","iopub.execute_input":"2022-04-27T18:30:15.544195Z","iopub.status.idle":"2022-04-27T18:30:15.568909Z","shell.execute_reply.started":"2022-04-27T18:30:15.544151Z","shell.execute_reply":"2022-04-27T18:30:15.567825Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nab_clf = AdaBoostClassifier(base_estimator=dt_clf, n_estimators=150, random_state=0)\nab_clf.fit(features, labels)\ny_pred = ab_clf.predict([[8,4]])\nscore  = ab_clf.score(features, labels)\nprint(\"Predicted Value\\n\", y_pred)\nprint(score)\nplot_model(features, labels, ab_clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:30:18.085138Z","iopub.execute_input":"2022-04-27T18:30:18.085411Z","iopub.status.idle":"2022-04-27T18:30:18.807923Z","shell.execute_reply.started":"2022-04-27T18:30:18.085387Z","shell.execute_reply":"2022-04-27T18:30:18.806693Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"From the above results we can analyse \"AdaBoost Classifier\" gives best results.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}